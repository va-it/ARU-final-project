{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the Jupyter Notebook for the MAGICODE project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First install some modules that are (usually) not installed by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.4.0-cp38-cp38-manylinux2010_x86_64.whl (394.8 MB)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/va281/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/va281/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages (from tensorflow) (0.36.2)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/va281/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/va281/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/va281/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages (from tensorflow) (0.36.2)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/va281/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting grpcio~=1.32.0\n",
      "  Using cached grpcio-1.32.0-cp38-cp38-manylinux2014_x86_64.whl (3.8 MB)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/va281/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting h5py~=2.10.0\n",
      "  Using cached h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/va281/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/va281/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting numpy~=1.19.2\n",
      "  Using cached numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Using cached protobuf-3.14.0-cp38-cp38-manylinux1_x86_64.whl (1.0 MB)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/va281/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting tensorboard~=2.4\n",
      "  Using cached tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/va281/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/va281/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (51.0.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/va281/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/va281/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/va281/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (51.0.0)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.0-py3-none-any.whl (12 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.7-py3-none-any.whl (34 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
      "  Using cached tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.2-py2.py3-none-any.whl (136 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Using cached wrapt-1.12.1-cp38-cp38-linux_x86_64.whl\n",
      "Installing collected packages: urllib3, pyasn1, idna, chardet, certifi, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, typing-extensions, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.2.0 certifi-2020.12.5 chardet-4.0.0 flatbuffers-1.12 gast-0.3.3 google-auth-1.24.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 idna-2.10 keras-preprocessing-1.1.2 markdown-3.3.3 numpy-1.19.5 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.14.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.7 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 urllib3-1.26.2 werkzeug-1.0.1 wrapt-1.12.1\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/home/va281/projects/python-stuff/jupyterenvironment/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0-py2.py3-none-any.whl\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-0.24.0-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/va281/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.0.0-py3-none-any.whl (302 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Using cached scipy-1.6.0-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/va281/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-1.0.0 scikit-learn-0.24.0 scipy-1.6.0 sklearn-0.0 threadpoolctl-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/home/va281/projects/python-stuff/jupyterenvironment/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.5.1.48-cp38-cp38-manylinux2014_x86_64.whl (50.4 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/va281/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages (from opencv-python) (1.19.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.1.48\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/home/va281/projects/python-stuff/jupyterenvironment/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "# install sklearn to use train_test_split function\n",
    "!pip install sklearn\n",
    "# install opencv to use cv2 module in get_preprocessed_img\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then import some libraries and modules that are needed for the code to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import sklearn.model_selection as model_selection\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files unzipped\n"
     ]
    }
   ],
   "source": [
    "os.chdir('datasets')\n",
    "# join the volumes together into a single zip file\n",
    "!zip -s 0 dataset.zip -O dataset_joined.zip\n",
    "# unzip the newly assembled archive into a folder called all_data\n",
    "!unzip dataset_joined.zip -d ./all_data\n",
    "\n",
    "if os.listdir('./all_data') :\n",
    "    print ('files unzipped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some values used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET_NAME = 'training_set'\n",
    "EVALUATION_SET_NAME = 'eval_set'\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 64\n",
    "CONTEXT_LENGTH = 48\n",
    "START_TOKEN = \"<START>\"\n",
    "END_TOKEN = \"<END>\"\n",
    "PLACEHOLDER = \" \"\n",
    "SEPARATOR = '->'\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into training and evaluation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: all_data/dataset/training_set\n",
      "Evaluation dataset: all_data/dataset/eval_set\n"
     ]
    }
   ],
   "source": [
    "# define source folder\n",
    "source = join('all_data', 'dataset')\n",
    "# get all file paths\n",
    "all_files = os.listdir(source)\n",
    "# build a generic image path (e.g. 'all_data/dataset/*.png')\n",
    "images_path = join(source, '*.png')\n",
    "# get all images paths\n",
    "img_files = glob.glob(images_path)\n",
    "# remove files extension from files paths\n",
    "img_files_without_extension = [Path(img_file).stem for img_file in img_files]\n",
    "\n",
    "# training set will be 6 times the size of the evaluation set\n",
    "distribution = 6\n",
    "\n",
    "# splits randomly the files into two sets\n",
    "train_set,eval_set = model_selection.train_test_split(img_files_without_extension, train_size=(distribution / 10))\n",
    "\n",
    "# create the TRAINING_SET_NAME and EVALUATION_SET_NAME directories if they do not exist\n",
    "if not os.path.exists(join(source, TRAINING_SET_NAME)):\n",
    "    os.makedirs(join(source, TRAINING_SET_NAME))\n",
    "if not os.path.exists(join(source, EVALUATION_SET_NAME)):\n",
    "    os.makedirs(join(source, EVALUATION_SET_NAME))\n",
    "\n",
    "# copy the files (img and gui) from the all_data folder into the training_set folder\n",
    "for file in train_set:\n",
    "    shutil.copyfile(join(source, file + '.png'), join(source, TRAINING_SET_NAME, file + '.png'))\n",
    "    shutil.copyfile(join(source, file + '.gui'), join(source, TRAINING_SET_NAME, file + '.gui'))\n",
    "\n",
    "# copy the files (img and gui) from the all_data folder into the eval_set folder\n",
    "for file in eval_set:\n",
    "    shutil.copyfile(join(source, file + '.png'), join(source, EVALUATION_SET_NAME, file + '.png'))\n",
    "    shutil.copyfile(join(source, file + '.gui'), join(source, EVALUATION_SET_NAME, file + '.gui'))\n",
    "\n",
    "print('Training dataset: {}'.format(join(source, TRAINING_SET_NAME)))\n",
    "print('Evaluation dataset: {}'.format(join(source, EVALUATION_SET_NAME)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some Classes and functions that will be used a few times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! REFACTOR - Remove unused functions, use .join etc.\n",
    "class Utils:\n",
    "    @staticmethod\n",
    "    def sparsify(label_vector, output_size):\n",
    "        sparse_vector = []\n",
    "\n",
    "        for label in label_vector:\n",
    "            sparse_label = np.zeros(output_size)\n",
    "            sparse_label[label] = 1\n",
    "\n",
    "            sparse_vector.append(sparse_label)\n",
    "\n",
    "        return np.array(sparse_vector)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_preprocessed_img(img_path, image_size):\n",
    "        import cv2\n",
    "        img = cv2.imread(img_path)\n",
    "        if not img is None:\n",
    "            img = cv2.resize(img, (image_size, image_size))\n",
    "            img = img.astype('float32')\n",
    "            img /= 255\n",
    "        return img\n",
    "    \n",
    "class Sampler:\n",
    "    def __init__(self, voc_path, input_shape, output_size, context_length):\n",
    "        self.voc = Vocabulary()\n",
    "        self.voc.retrieve(voc_path)\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.output_size = output_size\n",
    "\n",
    "        print('Vocabulary size: {}'.format(self.voc.size))\n",
    "        print('Input shape: {}'.format(self.input_shape))\n",
    "        print('Output size: {}'.format(self.output_size))\n",
    "\n",
    "        self.context_length = context_length\n",
    "\n",
    "    def predict_greedy(self, model, input_img, require_sparse_label=True, sequence_length=150, verbose=False):\n",
    "        current_context = [self.voc.vocabulary[PLACEHOLDER]] * (self.context_length - 1)\n",
    "        current_context.append(self.voc.vocabulary[START_TOKEN])\n",
    "        if require_sparse_label:\n",
    "            current_context = Utils.sparsify(current_context, self.output_size)\n",
    "\n",
    "        predictions = START_TOKEN\n",
    "        out_probas = []\n",
    "\n",
    "        for i in range(0, sequence_length):\n",
    "            if verbose:\n",
    "                print('predicting {}/{}...'.format(i, sequence_length))\n",
    "\n",
    "            probas = model.predict(input_img, np.array([current_context]))\n",
    "            prediction = np.argmax(probas)\n",
    "            out_probas.append(probas)\n",
    "\n",
    "            new_context = []\n",
    "            for j in range(1, self.context_length):\n",
    "                new_context.append(current_context[j])\n",
    "\n",
    "            if require_sparse_label:\n",
    "                sparse_label = np.zeros(self.output_size)\n",
    "                sparse_label[prediction] = 1\n",
    "                new_context.append(sparse_label)\n",
    "            else:\n",
    "                new_context.append(prediction)\n",
    "\n",
    "            current_context = new_context\n",
    "\n",
    "            predictions += self.voc.token_lookup[prediction]\n",
    "\n",
    "            if self.voc.token_lookup[prediction] == END_TOKEN:\n",
    "                break\n",
    "\n",
    "        return predictions, out_probas\n",
    "\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.binary_vocabulary = {}\n",
    "        self.vocabulary = {}\n",
    "        self.token_lookup = {}\n",
    "        self.size = 0\n",
    "\n",
    "        self.append(START_TOKEN)\n",
    "        self.append(END_TOKEN)\n",
    "        self.append(PLACEHOLDER)\n",
    "\n",
    "    def append(self, token):\n",
    "        if token not in self.vocabulary:\n",
    "            self.vocabulary[token] = self.size\n",
    "            self.token_lookup[self.size] = token\n",
    "            self.size += 1\n",
    "\n",
    "    def create_binary_representation(self):\n",
    "        if sys.version_info >= (3,):\n",
    "            items = self.vocabulary.items()\n",
    "        else:\n",
    "            items = self.vocabulary.iteritems()\n",
    "        for key, value in items:\n",
    "            binary = np.zeros(self.size)\n",
    "            binary[value] = 1\n",
    "            self.binary_vocabulary[key] = binary\n",
    "\n",
    "    def get_serialized_binary_representation(self):\n",
    "        if len(self.binary_vocabulary) == 0:\n",
    "            self.create_binary_representation()\n",
    "\n",
    "        string = ''\n",
    "        if sys.version_info >= (3,):\n",
    "            items = self.binary_vocabulary.items()\n",
    "        else:\n",
    "            items = self.binary_vocabulary.iteritems()\n",
    "        for key, value in items:\n",
    "            array_as_string = np.array2string(value, separator=',', max_line_width=self.size * self.size)\n",
    "            string += '{}{}{}\\n'.format(key, SEPARATOR, array_as_string[1:len(array_as_string) - 1])\n",
    "        return string\n",
    "\n",
    "    def save(self, path):\n",
    "        output_file_name = '{}/words.vocab'.format(path)\n",
    "        output_file = open(output_file_name, 'w')\n",
    "        output_file.write(self.get_serialized_binary_representation())\n",
    "        output_file.close()\n",
    "\n",
    "    def retrieve(self, path):\n",
    "        input_file = open('{}/words.vocab'.format(path), 'r')\n",
    "        buffer = ''\n",
    "        for line in input_file:\n",
    "            try:\n",
    "                separator_position = len(buffer) + line.index(SEPARATOR)\n",
    "                buffer += line\n",
    "                key = buffer[:separator_position]\n",
    "                value = buffer[separator_position + len(SEPARATOR):]\n",
    "                value = np.fromstring(value, sep=',')\n",
    "\n",
    "                self.binary_vocabulary[key] = value\n",
    "                self.vocabulary[key] = np.where(value == 1)[0][0]\n",
    "                self.token_lookup[np.where(value == 1)[0][0]] = key\n",
    "\n",
    "                buffer = ''\n",
    "            except ValueError:\n",
    "                buffer += line\n",
    "        input_file.close()\n",
    "        self.size = len(self.vocabulary)\n",
    "\n",
    "class Generator:\n",
    "    @staticmethod\n",
    "    def data_generator(voc, gui_paths, img_paths, batch_size, generate_binary_sequences=False, verbose=False, loop_only_one=False):\n",
    "        assert len(gui_paths) == len(img_paths)\n",
    "        voc.create_binary_representation()\n",
    "\n",
    "        while 1:\n",
    "            batch_input_images = []\n",
    "            batch_partial_sequences = []\n",
    "            batch_next_words = []\n",
    "            sample_in_batch_counter = 0\n",
    "\n",
    "            for i in range(0, len(gui_paths)):\n",
    "                if img_paths[i].find('.png') != -1:\n",
    "                    img = Utils.get_preprocessed_img(img_paths[i], IMAGE_SIZE)\n",
    "                else:\n",
    "                    img = np.load(img_paths[i])['features']\n",
    "                gui = open(gui_paths[i], 'r')\n",
    "\n",
    "                token_sequence = [START_TOKEN]\n",
    "                for line in gui:\n",
    "                    line = line.replace(',', ' ,').replace('\\n', ' \\n')\n",
    "                    tokens = line.split(' ')\n",
    "                    for token in tokens:\n",
    "                        voc.append(token)\n",
    "                        token_sequence.append(token)\n",
    "                token_sequence.append(END_TOKEN)\n",
    "\n",
    "                suffix = [PLACEHOLDER] * CONTEXT_LENGTH\n",
    "\n",
    "                a = np.concatenate([suffix, token_sequence])\n",
    "                for j in range(0, len(a) - CONTEXT_LENGTH):\n",
    "                    context = a[j:j + CONTEXT_LENGTH]\n",
    "                    label = a[j + CONTEXT_LENGTH]\n",
    "\n",
    "                    batch_input_images.append(img)\n",
    "                    batch_partial_sequences.append(context)\n",
    "                    batch_next_words.append(label)\n",
    "                    sample_in_batch_counter += 1\n",
    "\n",
    "                    if sample_in_batch_counter == batch_size or (loop_only_one and i == len(gui_paths) - 1):\n",
    "                        if verbose:\n",
    "                            print('Generating sparse vectors...')\n",
    "                        batch_next_words = Dataset.sparsify_labels(batch_next_words, voc)\n",
    "                        if generate_binary_sequences:\n",
    "                            batch_partial_sequences = Dataset.binarize(batch_partial_sequences, voc)\n",
    "                        else:\n",
    "                            batch_partial_sequences = Dataset.indexify(batch_partial_sequences, voc)\n",
    "\n",
    "                        if verbose:\n",
    "                            print('Convert arrays...')\n",
    "                        batch_input_images = np.array(batch_input_images)\n",
    "                        batch_partial_sequences = np.array(batch_partial_sequences)\n",
    "                        batch_next_words = np.array(batch_next_words)\n",
    "\n",
    "                        if verbose:\n",
    "                            print('Yield batch')\n",
    "                        yield ([batch_input_images, batch_partial_sequences], batch_next_words)\n",
    "\n",
    "                        batch_input_images = []\n",
    "                        batch_partial_sequences = []\n",
    "                        batch_next_words = []\n",
    "                        sample_in_batch_counter = 0\n",
    "                        \n",
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self.input_shape = None\n",
    "        self.output_size = None\n",
    "\n",
    "        self.ids = []\n",
    "        self.input_images = []\n",
    "        self.partial_sequences = []\n",
    "        self.next_words = []\n",
    "\n",
    "        self.voc = Vocabulary()\n",
    "        self.size = 0\n",
    "\n",
    "    @staticmethod\n",
    "    def load_paths_only(path):\n",
    "        print('Parsing data...')\n",
    "        gui_paths = []\n",
    "        img_paths = []\n",
    "        for f in os.listdir(path):\n",
    "            if f.find('.gui') != -1:\n",
    "                path_gui = join(path, f)\n",
    "                gui_paths.append(path_gui)\n",
    "                file_name = f[:f.find('.gui')]\n",
    "\n",
    "                if os.path.isfile(join(path, file_name + '.png')):\n",
    "                    path_img = format(path, file_name + '.png')\n",
    "                    img_paths.append(path_img)\n",
    "                elif os.path.isfile(join(path, file_name + '.npz')):\n",
    "                    path_img = join(path, file_name + '.npz')\n",
    "                    img_paths.append(path_img)\n",
    "\n",
    "        assert len(gui_paths) == len(img_paths)\n",
    "        return gui_paths, img_paths\n",
    "\n",
    "    def load(self, path, generate_binary_sequences=False):\n",
    "        print('Loading data...')\n",
    "        for f in os.listdir(path):\n",
    "            if f.find('.gui') != -1:\n",
    "                gui = open(join(path, f), 'r')\n",
    "                file_name = Path(f).stem\n",
    "                if os.path.isfile(join(path, file_name + '.png')):\n",
    "                    img = Utils.get_preprocessed_img(join(path, file_name + '.png'), IMAGE_SIZE)\n",
    "                    self.append(file_name, gui, img)\n",
    "                elif os.path.isfile(join(path, file_name + '.npz')):\n",
    "                    img = np.load(join(path, file_name + '.npz'))['features']\n",
    "                    self.append(file_name, gui, img)\n",
    "\n",
    "        print('Generating sparse vectors...')\n",
    "        self.voc.create_binary_representation()\n",
    "        self.next_words = self.sparsify_labels(self.next_words, self.voc)\n",
    "        if generate_binary_sequences:\n",
    "            self.partial_sequences = self.binarize(self.partial_sequences, self.voc)\n",
    "        else:\n",
    "            self.partial_sequences = self.indexify(self.partial_sequences, self.voc)\n",
    "\n",
    "        self.size = len(self.ids)\n",
    "        assert self.size == len(self.input_images) == len(self.partial_sequences) == len(self.next_words)\n",
    "        assert self.voc.size == len(self.voc.vocabulary)\n",
    "\n",
    "        print('Dataset size: {}'.format(self.size))\n",
    "        print('Vocabulary size: {}'.format(self.voc.size))\n",
    "\n",
    "        self.input_shape = self.input_images[0].shape\n",
    "        self.output_size = self.voc.size\n",
    "\n",
    "        print('Input shape: {}'.format(self.input_shape))\n",
    "        print('Output size: {}'.format(self.output_size))\n",
    "\n",
    "    def convert_arrays(self):\n",
    "        print('Convert arrays...')\n",
    "        self.input_images = np.array(self.input_images)\n",
    "        self.partial_sequences = np.array(self.partial_sequences)\n",
    "        self.next_words = np.array(self.next_words)\n",
    "\n",
    "    def append(self, sample_id, gui, img, to_show=False):\n",
    "        if to_show:\n",
    "            pic = img * 255\n",
    "            pic = np.array(pic, dtype=np.uint8)\n",
    "            Utils.show(pic)\n",
    "\n",
    "        token_sequence = [START_TOKEN]\n",
    "        for line in gui:\n",
    "            line = line.replace(',', ' ,').replace('\\n', ' \\n')\n",
    "            tokens = line.split(' ')\n",
    "            for token in tokens:\n",
    "                self.voc.append(token)\n",
    "                token_sequence.append(token)\n",
    "        token_sequence.append(END_TOKEN)\n",
    "\n",
    "        suffix = [PLACEHOLDER] * CONTEXT_LENGTH\n",
    "\n",
    "        a = np.concatenate([suffix, token_sequence])\n",
    "        for j in range(0, len(a) - CONTEXT_LENGTH):\n",
    "            context = a[j:j + CONTEXT_LENGTH]\n",
    "            label = a[j + CONTEXT_LENGTH]\n",
    "\n",
    "            self.ids.append(sample_id)\n",
    "            self.input_images.append(img)\n",
    "            self.partial_sequences.append(context)\n",
    "            self.next_words.append(label)\n",
    "\n",
    "    @staticmethod\n",
    "    def indexify(partial_sequences, voc):\n",
    "        temp = []\n",
    "        for sequence in partial_sequences:\n",
    "            sparse_vectors_sequence = []\n",
    "            for token in sequence:\n",
    "                sparse_vectors_sequence.append(voc.vocabulary[token])\n",
    "            temp.append(np.array(sparse_vectors_sequence))\n",
    "\n",
    "        return temp\n",
    "\n",
    "    @staticmethod\n",
    "    def binarize(partial_sequences, voc):\n",
    "        temp = []\n",
    "        for sequence in partial_sequences:\n",
    "            sparse_vectors_sequence = []\n",
    "            for token in sequence:\n",
    "                sparse_vectors_sequence.append(voc.binary_vocabulary[token])\n",
    "            temp.append(np.array(sparse_vectors_sequence))\n",
    "\n",
    "        return temp\n",
    "\n",
    "    @staticmethod\n",
    "    def sparsify_labels(next_words, voc):\n",
    "        temp = []\n",
    "        for label in next_words:\n",
    "            temp.append(voc.binary_vocabulary[label])\n",
    "\n",
    "        return temp\n",
    "\n",
    "    def save_metadata(self, path):\n",
    "        np.save(join(path, 'meta_dataset'), np.array([self.input_shape, self.output_size, self.size], dtype=object), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform training set into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define source and destination folders\n",
    "source = join('all_data', 'dataset', 'training_set')\n",
    "destination = join('all_data', 'dataset', 'training_features')\n",
    "\n",
    "# create the training_features directory if it does not exist\n",
    "if not os.path.exists(destination):\n",
    "    os.makedirs(destination)\n",
    "\n",
    "# transform images in training dataset (i.e. normalized pixel values and resized pictures) to numpy arrays (smaller files, useful if uploading the set to train a model in the cloud)\n",
    "for f in os.listdir(source):\n",
    "    if f.find('.png') != -1:\n",
    "        img = Utils.get_preprocessed_img(join(source, f), IMAGE_SIZE)\n",
    "        file_name = f[:f.find('.png')]\n",
    "\n",
    "        np.savez_compressed(join(destination, file_name), features=img)\n",
    "        retrieve = np.load(join(destination, file_name + '.npz'))['features']\n",
    "        \n",
    "        assert np.array_equal(img, retrieve)\n",
    "        \n",
    "        shutil.copyfile(join(source, file_name + '.gui'), join(destination, file_name + '.gui'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')\n",
    "if not os.path.exists('bin'):\n",
    "    os.mkdir('bin')\n",
    "os.chdir('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare magicode class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout, \\\n",
    "                         RepeatVector, LSTM, concatenate, \\\n",
    "                         Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Sequential, Model, model_from_json\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from tensorflow.keras import *\n",
    "\n",
    "class magicode:\n",
    "    def __init__(self, input_shape, output_size, output_path):\n",
    "        self.model = None\n",
    "        self.name = 'magicode'\n",
    "        self.input_shape = input_shape\n",
    "        self.output_size = output_size\n",
    "        self.output_path = output_path\n",
    "\n",
    "        image_model = Sequential()\n",
    "        image_model.add(Conv2D(32, (3, 3), padding='valid', activation='relu', input_shape=input_shape))\n",
    "        image_model.add(Conv2D(32, (3, 3), padding='valid', activation='relu'))\n",
    "        image_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        image_model.add(Dropout(0.25))\n",
    "\n",
    "        image_model.add(Conv2D(64, (3, 3), padding='valid', activation='relu'))\n",
    "        image_model.add(Conv2D(64, (3, 3), padding='valid', activation='relu'))\n",
    "        image_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        image_model.add(Dropout(0.25))\n",
    "\n",
    "        image_model.add(Conv2D(128, (3, 3), padding='valid', activation='relu'))\n",
    "        image_model.add(Conv2D(128, (3, 3), padding='valid', activation='relu'))\n",
    "        image_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        image_model.add(Dropout(0.25))\n",
    "\n",
    "        image_model.add(Flatten())\n",
    "        image_model.add(Dense(1024, activation='relu'))\n",
    "        image_model.add(Dropout(0.3))\n",
    "        image_model.add(Dense(1024, activation='relu'))\n",
    "        image_model.add(Dropout(0.3))\n",
    "\n",
    "        image_model.add(RepeatVector(CONTEXT_LENGTH))\n",
    "\n",
    "        visual_input = Input(shape=input_shape)\n",
    "        encoded_image = image_model(visual_input)\n",
    "\n",
    "        language_model = Sequential()\n",
    "        language_model.add(LSTM(128, return_sequences=True, input_shape=(CONTEXT_LENGTH, output_size)))\n",
    "        language_model.add(LSTM(128, return_sequences=True))\n",
    "\n",
    "        textual_input = Input(shape=(CONTEXT_LENGTH, output_size))\n",
    "        encoded_text = language_model(textual_input)\n",
    "\n",
    "        decoder = concatenate([encoded_image, encoded_text])\n",
    "\n",
    "        decoder = LSTM(512, return_sequences=True)(decoder)\n",
    "        decoder = LSTM(512, return_sequences=False)(decoder)\n",
    "        decoder = Dense(output_size, activation='softmax')(decoder)\n",
    "\n",
    "        self.model = Model(inputs=[visual_input, textual_input], outputs=decoder)\n",
    "\n",
    "        optimizer = RMSprop(lr=0.0001, clipvalue=1.0)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def fit_generator(self, generator, steps_per_epoch):\n",
    "        self.model.fit(generator, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, verbose=1)\n",
    "        self.save()\n",
    "\n",
    "    def predict(self, image, partial_caption):\n",
    "        return self.model.predict([image, partial_caption], verbose=0)[0]\n",
    "\n",
    "    def save(self):\n",
    "        model_json = self.model.to_json()\n",
    "        with open(format(self.output_path, self.name, '.json'), \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        self.model.save_weights(join(self.output_path, self.name, '.h5'))\n",
    "\n",
    "    def load(self, name=\"\"):\n",
    "        output_name = self.name if name == \"\" else name\n",
    "        with open(join(self.output_path, output_name, '.json'), \"r\") as json_file:\n",
    "            loaded_model_json = json_file.read()\n",
    "        self.model = model_from_json(loaded_model_json)\n",
    "        self.model.load_weights(join(self.output_path, output_name, '.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model using a generator (to avoid having to fit all the data in memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Generating sparse vectors...\n",
      "Dataset size: 5250\n",
      "Vocabulary size: 26\n",
      "Input shape: (256, 256, 3)\n",
      "Output size: 26\n",
      "Parsing data...\n",
      "Epoch 1/10\n",
      " 2/82 [..............................] - ETA: 12:47 - loss: 3.1045"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-16c4bbf90bd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-56506460e518>\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/python-stuff/jupyterenvironment/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "training_features = join('..', 'datasets', 'all_data', 'dataset', 'training_features')\n",
    "output_path = join('..', 'bin')\n",
    "\n",
    "dataset = Dataset()\n",
    "dataset.load(training_features, generate_binary_sequences=True)\n",
    "dataset.save_metadata(output_path)\n",
    "dataset.voc.save(output_path)\n",
    "\n",
    "gui_paths, img_paths = Dataset.load_paths_only(training_features)\n",
    "\n",
    "input_shape = dataset.input_shape\n",
    "output_size = dataset.output_size\n",
    "steps_per_epoch = dataset.size / BATCH_SIZE\n",
    "voc = Vocabulary()\n",
    "voc.retrieve(output_path)\n",
    "\n",
    "generator = Generator.data_generator(voc, gui_paths, img_paths, batch_size=BATCH_SIZE, generate_binary_sequences=True)\n",
    "\n",
    "model = magicode(input_shape, output_size, output_path)\n",
    "\n",
    "model.fit_generator(generator, steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the directories for storing screenshots to \"decode\" and the resulting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step out of model directory\n",
    "os.chdir('..')\n",
    "# create directory to store images to be \"decoded\"\n",
    "if not os.path.exists('screenshots'):\n",
    "    os.mkdir('screenshots')\n",
    "# create directory to store code generated by \"decoding\" images in screenshots folder \n",
    "if not os.path.exists('code'):\n",
    "    os.mkdir('code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the code for provided screenshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() got an unexpected keyword argument 'allow_pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-7469f0054110>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maskopenfilename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmeta_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_weights_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'meta_dataset.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0moutput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: join() got an unexpected keyword argument 'allow_pickle'"
     ]
    }
   ],
   "source": [
    "from tkinter.filedialog import askopenfilename\n",
    "\n",
    "trained_weights_path = 'bin'\n",
    "trained_model_name = 'magicode'\n",
    "input_path = 'screenshots'\n",
    "output_path = 'code'\n",
    "\n",
    "file_name = askopenfilename()\n",
    "\n",
    "meta_dataset = np.load(join(trained_weights_path, 'meta_dataset.npy'), allow_pickle=True)\n",
    "input_shape = meta_dataset[0]\n",
    "output_size = meta_dataset[1]\n",
    "\n",
    "model = magicode(input_shape, output_size, trained_weights_path)\n",
    "model.load(trained_model_name)\n",
    "\n",
    "sampler = Sampler(trained_weights_path, input_shape, output_size, CONTEXT_LENGTH)\n",
    "\n",
    "for f in os.listdir(input_path):\n",
    "    if f.find('.png') != -1:\n",
    "        evaluation_img = get_preprocessed_img(join(input_path,p), IMAGE_SIZE)\n",
    "\n",
    "        file_name = f[:f.find('.png')]\n",
    "\n",
    "        result, _ = sampler.predict_greedy(model, np.array([evaluation_img]))\n",
    "        print('Result greedy: {}'.format(result))\n",
    "\n",
    "        with open(join(output_path, file_name + '.gui'), 'w') as out_f:\n",
    "            out_f.write(result.replace(START_TOKEN, '').replace(END_TOKEN, ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from classes.Node import *\n",
    "\n",
    "class Compiler:\n",
    "    def __init__(self, dsl_mapping_file_path):\n",
    "        with open(dsl_mapping_file_path) as data_file:\n",
    "            self.dsl_mapping = json.load(data_file)\n",
    "\n",
    "        self.opening_tag = self.dsl_mapping['opening-tag']\n",
    "        self.closing_tag = self.dsl_mapping['closing-tag']\n",
    "        self.content_holder = self.opening_tag + self.closing_tag\n",
    "\n",
    "        self.root = Node('body', None, self.content_holder)\n",
    "\n",
    "    def compile(self, input_file_path, output_file_path, rendering_function=None):\n",
    "        dsl_file = open(input_file_path)\n",
    "        current_parent = self.root\n",
    "\n",
    "        for token in dsl_file:\n",
    "            token = token.replace(' ', '').replace('\\n', '')\n",
    "\n",
    "            if token.find(self.opening_tag) != -1:\n",
    "                token = token.replace(self.opening_tag, '')\n",
    "\n",
    "                element = Node(token, current_parent, self.content_holder)\n",
    "                current_parent.add_child(element)\n",
    "                current_parent = element\n",
    "            elif token.find(self.closing_tag) != -1:\n",
    "                current_parent = current_parent.parent\n",
    "            else:\n",
    "                tokens = token.split(',')\n",
    "                for t in tokens:\n",
    "                    element = Node(t, current_parent, self.content_holder)\n",
    "                    current_parent.add_child(element)\n",
    "\n",
    "        output_html = self.root.render(self.dsl_mapping, rendering_function=rendering_function)\n",
    "        with open(output_file_path, 'w') as output_file:\n",
    "            output_file.write(output_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the generated code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILL_WITH_RANDOM_TEXT = True\n",
    "TEXT_PLACE_HOLDER = '[]'\n",
    "\n",
    "dsl_path = join('compiler','assets','dsl-mappgin.json')\n",
    "compiler = Compiler(dsl_path)\n",
    "\n",
    "def render_content_with_text(key, value):\n",
    "    text_inputs = ['input-text', 'input-password']\n",
    "    control_inputs = ['input-checkbox', 'input-radio']\n",
    "    if FILL_WITH_RANDOM_TEXT:\n",
    "        if key.find('btn') != -1:\n",
    "            value = value.replace(TEXT_PLACE_HOLDER, Utils.get_random_text())\n",
    "        elif key.find('title') != -1:\n",
    "            value = value.replace(TEXT_PLACE_HOLDER, Utils.get_random_text(length_text=5, space_number=0))\n",
    "        elif key.find('text') != -1:\n",
    "            value = value.replace(TEXT_PLACE_HOLDER,\n",
    "                                  Utils.get_random_text(length_text=56, space_number=7, with_upper_case=False))\n",
    "        elif any(text_input in key for text_input in text_inputs):\n",
    "            value = value.replace(TEXT_PLACE_HOLDER, Utils.get_random_text(length_text=30, space_number=0))\n",
    "        elif any(control_input in key for control_input in control_inputs):\n",
    "            value = value.replace(TEXT_PLACE_HOLDER, Utils.get_random_text(length_text=10, space_number=0))\n",
    "    return value\n",
    "\n",
    "path = 'code'\n",
    "generated_code_files = os.listdir(path)\n",
    "\n",
    "for file in generated_code_files:\n",
    "    file_uid = Path(file).stem\n",
    "    input_file_path = join(path, file_uid, '.gui')\n",
    "    output_file_path = join(path, file_uid, '.html')\n",
    "\n",
    "    compiler.compile(input_file_path, output_file_path, rendering_function=render_content_with_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
