{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the Jupyter Notebook for the MAGICODE project - TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we import some libraries and modules that we will need for the code to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import sklearn.model_selection as model_selection\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then we install the modules that are (usually) not installed by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install sklearn to use train_test_split function\n",
    "!pip install sklearn\n",
    "# install opencv to use cv2 module in get_preprocessed_img\n",
    "!pip install opencv-python\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('datasets')\n",
    "# join the volumes together into a single zip file\n",
    "!zip -s 0 dataset.zip -O dataset_joined.zip\n",
    "# unzip the newly assembled archive\n",
    "!unzip dataset_joined.zip -d ./all_data\n",
    "print ('files unzipped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some values used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET_NAME = 'training_set'\n",
    "EVALUATION_SET_NAME = 'eval_set'\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 64\n",
    "CONTEXT_LENGTH = 48\n",
    "START_TOKEN = \"<START>\"\n",
    "END_TOKEN = \"<END>\"\n",
    "PLACEHOLDER = \" \"\n",
    "SEPARATOR = '->'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into training and evaluation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define source folder\n",
    "source = join('all_data', 'dataset')\n",
    "# get all file paths\n",
    "all_files = os.listdir(source)\n",
    "# build a generic image path (e.g. 'all_data/dataset/*.png')\n",
    "images_path = join(source, '*.png')\n",
    "# get all images paths\n",
    "img_files = glob.glob(images_path)\n",
    "# remove files extension from files paths\n",
    "img_files_without_extension = [Path(img_file).stem for img_file in img_files]\n",
    "\n",
    "# training set will be 6 times the size of the evaluation set\n",
    "distribution = 6\n",
    "\n",
    "# splits randomly the files into two sets\n",
    "# Path(*).stem returns the file name without extension\n",
    "train_set,eval_set = model_selection.train_test_split(img_files_without_extension, train_size=(distribution / 10))\n",
    "\n",
    "# create the TRAINING_SET_NAME and EVALUATION_SET_NAME directories if they do not exist\n",
    "if not os.path.exists(join(source, TRAINING_SET_NAME)):\n",
    "    os.makedirs(join(source, TRAINING_SET_NAME))\n",
    "if not os.path.exists(join(source, EVALUATION_SET_NAME)):\n",
    "    os.makedirs(join(source, EVALUATION_SET_NAME))\n",
    "\n",
    "# copy the files (img and gui) from the all_data folder into the training_set folder\n",
    "for file in train_set:\n",
    "    shutil.copyfile(join(source, file + '.png'), join(source, TRAINING_SET_NAME, file + '.png'))\n",
    "    shutil.copyfile(join(source, file + '.gui'), join(source, TRAINING_SET_NAME, file + '.gui'))\n",
    "\n",
    "# copy the files (img and gui) from the all_data folder into the eval_set folder\n",
    "for file in eval_set:\n",
    "    shutil.copyfile(join(source, file + '.png'), join(source, EVALUATION_SET_NAME, file + '.png'))\n",
    "    shutil.copyfile(join(source, file + '.gui'), join(source, EVALUATION_SET_NAME, file + '.gui'))\n",
    "\n",
    "print('Training dataset: {}'.format(join(source, TRAINING_SET_NAME)))\n",
    "print('Evaluation dataset: {}'.format(join(source, EVALUATION_SET_NAME)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some Classes and functions that will be used a few times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! REFACTOR - Remove unused functions, use .join etc.\n",
    "class Utils:\n",
    "    @staticmethod\n",
    "    def sparsify(label_vector, output_size):\n",
    "        sparse_vector = []\n",
    "\n",
    "        for label in label_vector:\n",
    "            sparse_label = np.zeros(output_size)\n",
    "            sparse_label[label] = 1\n",
    "\n",
    "            sparse_vector.append(sparse_label)\n",
    "\n",
    "        return np.array(sparse_vector)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_preprocessed_img(img_path, image_size):\n",
    "        import cv2\n",
    "        img = cv2.imread(img_path)\n",
    "        if not img is None:\n",
    "            img = cv2.resize(img, (image_size, image_size))\n",
    "            img = img.astype('float32')\n",
    "            img /= 255\n",
    "        return img\n",
    "    \n",
    "class Sampler:\n",
    "    def __init__(self, voc_path, input_shape, output_size, context_length):\n",
    "        self.voc = Vocabulary()\n",
    "        self.voc.retrieve(voc_path)\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.output_size = output_size\n",
    "\n",
    "        print(\"Vocabulary size: {}\".format(self.voc.size))\n",
    "        print(\"Input shape: {}\".format(self.input_shape))\n",
    "        print(\"Output size: {}\".format(self.output_size))\n",
    "\n",
    "        self.context_length = context_length\n",
    "\n",
    "    def predict_greedy(self, model, input_img, require_sparse_label=True, sequence_length=150, verbose=False):\n",
    "        current_context = [self.voc.vocabulary[PLACEHOLDER]] * (self.context_length - 1)\n",
    "        current_context.append(self.voc.vocabulary[START_TOKEN])\n",
    "        if require_sparse_label:\n",
    "            current_context = Utils.sparsify(current_context, self.output_size)\n",
    "\n",
    "        predictions = START_TOKEN\n",
    "        out_probas = []\n",
    "\n",
    "        for i in range(0, sequence_length):\n",
    "            if verbose:\n",
    "                print(\"predicting {}/{}...\".format(i, sequence_length))\n",
    "\n",
    "            probas = model.predict(input_img, np.array([current_context]))\n",
    "            prediction = np.argmax(probas)\n",
    "            out_probas.append(probas)\n",
    "\n",
    "            new_context = []\n",
    "            for j in range(1, self.context_length):\n",
    "                new_context.append(current_context[j])\n",
    "\n",
    "            if require_sparse_label:\n",
    "                sparse_label = np.zeros(self.output_size)\n",
    "                sparse_label[prediction] = 1\n",
    "                new_context.append(sparse_label)\n",
    "            else:\n",
    "                new_context.append(prediction)\n",
    "\n",
    "            current_context = new_context\n",
    "\n",
    "            predictions += self.voc.token_lookup[prediction]\n",
    "\n",
    "            if self.voc.token_lookup[prediction] == END_TOKEN:\n",
    "                break\n",
    "\n",
    "        return predictions, out_probas\n",
    "\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.binary_vocabulary = {}\n",
    "        self.vocabulary = {}\n",
    "        self.token_lookup = {}\n",
    "        self.size = 0\n",
    "\n",
    "        self.append(START_TOKEN)\n",
    "        self.append(END_TOKEN)\n",
    "        self.append(PLACEHOLDER)\n",
    "\n",
    "    def append(self, token):\n",
    "        if token not in self.vocabulary:\n",
    "            self.vocabulary[token] = self.size\n",
    "            self.token_lookup[self.size] = token\n",
    "            self.size += 1\n",
    "\n",
    "    def create_binary_representation(self):\n",
    "        if sys.version_info >= (3,):\n",
    "            items = self.vocabulary.items()\n",
    "        else:\n",
    "            items = self.vocabulary.iteritems()\n",
    "        for key, value in items:\n",
    "            binary = np.zeros(self.size)\n",
    "            binary[value] = 1\n",
    "            self.binary_vocabulary[key] = binary\n",
    "\n",
    "    def get_serialized_binary_representation(self):\n",
    "        if len(self.binary_vocabulary) == 0:\n",
    "            self.create_binary_representation()\n",
    "\n",
    "        string = \"\"\n",
    "        if sys.version_info >= (3,):\n",
    "            items = self.binary_vocabulary.items()\n",
    "        else:\n",
    "            items = self.binary_vocabulary.iteritems()\n",
    "        for key, value in items:\n",
    "            array_as_string = np.array2string(value, separator=',', max_line_width=self.size * self.size)\n",
    "            string += \"{}{}{}\\n\".format(key, SEPARATOR, array_as_string[1:len(array_as_string) - 1])\n",
    "        return string\n",
    "\n",
    "    def save(self, path):\n",
    "        output_file_name = \"{}/words.vocab\".format(path)\n",
    "        output_file = open(output_file_name, 'w')\n",
    "        output_file.write(self.get_serialized_binary_representation())\n",
    "        output_file.close()\n",
    "\n",
    "    def retrieve(self, path):\n",
    "        input_file = open(\"{}/words.vocab\".format(path), 'r')\n",
    "        buffer = \"\"\n",
    "        for line in input_file:\n",
    "            try:\n",
    "                separator_position = len(buffer) + line.index(SEPARATOR)\n",
    "                buffer += line\n",
    "                key = buffer[:separator_position]\n",
    "                value = buffer[separator_position + len(SEPARATOR):]\n",
    "                value = np.fromstring(value, sep=',')\n",
    "\n",
    "                self.binary_vocabulary[key] = value\n",
    "                self.vocabulary[key] = np.where(value == 1)[0][0]\n",
    "                self.token_lookup[np.where(value == 1)[0][0]] = key\n",
    "\n",
    "                buffer = \"\"\n",
    "            except ValueError:\n",
    "                buffer += line\n",
    "        input_file.close()\n",
    "        self.size = len(self.vocabulary)\n",
    "\n",
    "class Generator:\n",
    "    @staticmethod\n",
    "    def data_generator(voc, gui_paths, img_paths, batch_size, generate_binary_sequences=False, verbose=False, loop_only_one=False):\n",
    "        assert len(gui_paths) == len(img_paths)\n",
    "        voc.create_binary_representation()\n",
    "\n",
    "        while 1:\n",
    "            batch_input_images = []\n",
    "            batch_partial_sequences = []\n",
    "            batch_next_words = []\n",
    "            sample_in_batch_counter = 0\n",
    "\n",
    "            for i in range(0, len(gui_paths)):\n",
    "                if img_paths[i].find(\".png\") != -1:\n",
    "                    img = Utils.get_preprocessed_img(img_paths[i], IMAGE_SIZE)\n",
    "                else:\n",
    "                    img = np.load(img_paths[i])[\"features\"]\n",
    "                gui = open(gui_paths[i], 'r')\n",
    "\n",
    "                token_sequence = [START_TOKEN]\n",
    "                for line in gui:\n",
    "                    line = line.replace(\",\", \" ,\").replace(\"\\n\", \" \\n\")\n",
    "                    tokens = line.split(\" \")\n",
    "                    for token in tokens:\n",
    "                        voc.append(token)\n",
    "                        token_sequence.append(token)\n",
    "                token_sequence.append(END_TOKEN)\n",
    "\n",
    "                suffix = [PLACEHOLDER] * CONTEXT_LENGTH\n",
    "\n",
    "                a = np.concatenate([suffix, token_sequence])\n",
    "                for j in range(0, len(a) - CONTEXT_LENGTH):\n",
    "                    context = a[j:j + CONTEXT_LENGTH]\n",
    "                    label = a[j + CONTEXT_LENGTH]\n",
    "\n",
    "                    batch_input_images.append(img)\n",
    "                    batch_partial_sequences.append(context)\n",
    "                    batch_next_words.append(label)\n",
    "                    sample_in_batch_counter += 1\n",
    "\n",
    "                    if sample_in_batch_counter == batch_size or (loop_only_one and i == len(gui_paths) - 1):\n",
    "                        if verbose:\n",
    "                            print(\"Generating sparse vectors...\")\n",
    "                        batch_next_words = Dataset.sparsify_labels(batch_next_words, voc)\n",
    "                        if generate_binary_sequences:\n",
    "                            batch_partial_sequences = Dataset.binarize(batch_partial_sequences, voc)\n",
    "                        else:\n",
    "                            batch_partial_sequences = Dataset.indexify(batch_partial_sequences, voc)\n",
    "\n",
    "                        if verbose:\n",
    "                            print(\"Convert arrays...\")\n",
    "                        batch_input_images = np.array(batch_input_images)\n",
    "                        batch_partial_sequences = np.array(batch_partial_sequences)\n",
    "                        batch_next_words = np.array(batch_next_words)\n",
    "\n",
    "                        if verbose:\n",
    "                            print(\"Yield batch\")\n",
    "                        yield ([batch_input_images, batch_partial_sequences], batch_next_words)\n",
    "\n",
    "                        batch_input_images = []\n",
    "                        batch_partial_sequences = []\n",
    "                        batch_next_words = []\n",
    "                        sample_in_batch_counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform training set into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define source and destination folders\n",
    "source = join('all_data', 'dataset', 'training_set')\n",
    "destination = join('all_data', 'dataset', 'training_features')\n",
    "\n",
    "# create the training_features directory if it does not exist\n",
    "if not os.path.exists(destination):\n",
    "    os.makedirs(destination)\n",
    "\n",
    "# transform images in training dataset (i.e. normalized pixel values and resized pictures) to numpy arrays (smaller files, useful if uploading the set to train a model in the cloud)\n",
    "for f in os.listdir(source):\n",
    "    if f.find('.png') != -1:\n",
    "        img = Utils.get_preprocessed_img(join(source, f), IMAGE_SIZE)\n",
    "        file_name = f[:f.find('.png')]\n",
    "\n",
    "        np.savez_compressed(join(destination, file_name), features=img)\n",
    "        retrieve = np.load(join(destination, file_name + '.npz'))['features']\n",
    "        \n",
    "        assert np.array_equal(img, retrieve)\n",
    "        \n",
    "        shutil.copyfile(join(source, file_name + '.gui'), join(destination, file_name + '.gui'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')\n",
    "if not os.path.exists('bin'):\n",
    "    os.mkdir('bin')\n",
    "os.chdir('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model using a generator (to avoid having to fit all the data in memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "\n",
    "from classes.model.pix2code import *\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "training_features = join('..', 'datasets', 'all_data', 'dataset', 'training_features')\n",
    "output_path = join('..', 'bin')\n",
    "\n",
    "dataset = Dataset()\n",
    "dataset.load(training_features, generate_binary_sequences=True)\n",
    "dataset.save_metadata(output_path)\n",
    "dataset.voc.save(output_path)\n",
    "\n",
    "gui_paths, img_paths = Dataset.load_paths_only(training_features)\n",
    "\n",
    "input_shape = dataset.input_shape\n",
    "output_size = dataset.output_size\n",
    "steps_per_epoch = dataset.size / BATCH_SIZE\n",
    "voc = Vocabulary()\n",
    "voc.retrieve(output_path)\n",
    "\n",
    "generator = Generator.data_generator(voc, gui_paths, img_paths, batch_size=BATCH_SIZE, generate_binary_sequences=True)\n",
    "\n",
    "model = pix2code(input_shape, output_size, output_path)\n",
    "\n",
    "model.fit_generator(generator, steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the directories for storing screenshots to \"decode\" and the resulting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step out of model directory\n",
    "os.chdir('..')\n",
    "# create directory to store images to be \"decoded\"\n",
    "if not os.path.exists('screenshots'):\n",
    "    os.mkdir('screenshots')\n",
    "# create directory to store code generated by \"decoding\" images in screenshots folder \n",
    "if not os.path.exists('code'):\n",
    "    os.mkdir('code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the code for provided screenshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! DECLARE MODEL ABOVE\n",
    "from classes.model.pix2code import *\n",
    "\n",
    "trained_weights_path = 'bin'\n",
    "trained_model_name = 'pix2code'\n",
    "input_path = 'screenshots'\n",
    "output_path = 'code'\n",
    "\n",
    "meta_dataset = np.load(join(trained_weights_path, 'meta_dataset.npy'))\n",
    "input_shape = meta_dataset[0]\n",
    "output_size = meta_dataset[1]\n",
    "\n",
    "model = pix2code(input_shape, output_size, trained_weights_path)\n",
    "model.load(trained_model_name)\n",
    "\n",
    "sampler = Sampler(trained_weights_path, input_shape, output_size, CONTEXT_LENGTH)\n",
    "\n",
    "for f in os.listdir(input_path):\n",
    "    if f.find('.png') != -1:\n",
    "        evaluation_img = get_preprocessed_img(join(input_path,p), IMAGE_SIZE)\n",
    "\n",
    "        file_name = f[:f.find('.png')]\n",
    "\n",
    "        result, _ = sampler.predict_greedy(model, np.array([evaluation_img]))\n",
    "        print('Result greedy: {}'.format(result))\n",
    "\n",
    "        with open(join(output_path, file_name + '.gui'), 'w') as out_f:\n",
    "            out_f.write(result.replace(START_TOKEN, '').replace(END_TOKEN, ''))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
